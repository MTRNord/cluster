---
apiVersion: v1
kind: Namespace
metadata:
  name: matrix-postgres-cluster
---
apiVersion: acid.zalan.do/v1
kind: postgresql
metadata:
  labels:
    team: matrix
  name: matrix-postgres-cluster
  namespace: matrix-postgres-cluster
spec:
  tolerations:
    - key: "arch"
      operator: "Equal"
      value: "arm64"
      effect: "NoSchedule"
  enableShmVolume: true
  databases:
    synapse: synapse
    draupnir_synapse: draupnir_synapse
    matrix_media_repo: matrix_media_repo
    syncv3: syncv3
    signal_bridge: signal_bridge
    instagram_bridge: instagram_bridge
    zammad: zammad
    bench: bench
    paperless: paperless
    umami: umami
    authentik: authentik
  numberOfInstances: 3
  resources:
    requests:
      cpu: 150m
      memory: 5Gi
    limits:
      cpu: 2000m
      memory: 10Gi
  postgresql:
    version: "15"
    parameters:
      # Connectivity
      max_connections: "340"
      superuser_reserved_connections: "3"

      # Memory settings
      shared_buffers: "4GB"
      work_mem: "32 MB"
      maintenance_work_mem: "1GB"
      huge_pages: off
      effective_cache_size: "11 GB"
      effective_io_concurrency: "150"
      random_page_cost: "1.5"

      # Cost of a sequentially-fetched disk page
      seq_page_cost: "0.7"
      # Cost of processing each row in a query
      cpu_tuple_cost: "0.01"

      # Cost of processing each index entry during an index scan
      cpu_index_tuple_cost: "0.005"

      # Cost of processing each operator or function executed during a query
      cpu_operator_cost: "0.0025"

      # Cost of setting up parallel workers for a parallel operation
      parallel_setup_cost: "1000.0"

      # Minimum amount of table data for a parallel scan to be considered
      min_parallel_table_scan_size: "8MB"


      # Monitoring
      shared_preload_libraries: "pg_buffercache,pg_stat_statements"
      track_io_timing: on
      track_functions: pl

      # Replication
      wal_level: replica
      max_wal_senders: "10"
      synchronous_commit: on

      # Checkpointing
      checkpoint_timeout: "15 min"
      checkpoint_completion_target: "0.9"
      min_wal_size: "1GB"
      max_wal_size: "8GB"

      # archive_mode: on # having it on enables activating P.I.T.R. at a later time without restart
      # archive_command: "/bin/true" # not doing anything yet with WAL-s

      password_encryption: scram-sha-256

      # WAL writing
      wal_compression: "on"
      wal_buffers: "-1"
      wal_writer_delay: 200ms
      wal_writer_flush_after: 1MB
      wal_keep_size: "3650 MB"

      # Background writer
      bgwriter_delay: 200ms
      bgwriter_lru_maxpages: "100"
      bgwriter_lru_multiplier: "2.0"
      bgwriter_flush_after: "0"

      # Parallel queries
      max_worker_processes: "12"
      max_parallel_workers_per_gather: "6"
      max_parallel_maintenance_workers: "6"
      max_parallel_workers: "12"
      parallel_leader_participation: "on"

      # Advanced features
      enable_partitionwise_join: "on"
      enable_partitionwise_aggregate: "on"
      jit: "on"
      max_slot_wal_keep_size: "1000 MB"
      track_wal_io_timing: "on"
      maintenance_io_concurrency: "150"
      wal_recycle: "on"

      autovacuum_analyze_scale_factor: "0.05"
      autovacuum_vacuum_scale_factor: "0.02"
      autovacuum_vacuum_cost_limit: "400"
      vacuum_cost_limit: "300"

  teamId: matrix
  users:
    synapse: []
    draupnir_synapse: []
    matrix_media_repo: []
    syncv3: []
    signal_bridge: []
    instagram_bridge: []
    zammad: []
    bench: []
    paperless: []
    umami: []
    authentik: []
  volume:
    size: 50Gi
    #    storageClass: nfs-client
    storageClass: local-hostpath
  # additionalVolumes:
  #   - name: hugepage
  #     mountPath: /hugepages
  #     volumeSource:
  #       emptyDir:
  #         medium: HugePages

  patroni:
    ttl: 30
    loop_wait: 10
    retry_timeout: 10
    failsafe_mode: true
    synchronous_mode: true
    synchronous_mode_strict: false
    synchronous_node_count: 1
    maximum_lag_on_failover: 150
